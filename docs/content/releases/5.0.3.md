---
title: "5.0.3"
date:
draft: false
weight: 897
---


Crunchy Data announces the release of [Crunchy Postgres for Kubernetes](https://www.crunchydata.com/products/crunchy-postgresql-for-kubernetes/) 5.0.3.

Crunchy Postgres for Kubernetes is powered by [PGO](https://github.com/CrunchyData/postgres-operator), the open source [Postgres Operator](https://github.com/CrunchyData/postgres-operator) from [Crunchy Data](https://www.crunchydata.com). [PGO](https://github.com/CrunchyData/postgres-operator) is released in conjunction with the [Crunchy Container Suite](https://github.com/CrunchyData/container-suite).

Crunchy Postgres for Kubernetes 5.0.3 includes the following software versions upgrades:

- PostgreSQL 14 is now available.
- pgBackRest is updated to version 2.35.
- Patroni is updated to version 2.1.1.
- The [pgAudit](https://github.com/pgaudit/pgaudit) extension is now at version 1.6.0.
- The [pgAudit Analyze](https://github.com/pgaudit/pgaudit_analyze) extension is now at version 1.0.8.
- The [pgnodemx](https://github.com/CrunchyData/pgnodemx) extension is now at version 1.0.5.
- The [set_user](https://github.com/pgaudit/set_user) extension is now at version 3.0.0.
- The [wal2json](https://github.com/eulerto/wal2json) extension is now at version 2.4.

Read more about how you can [get started]({{< relref "quickstart/_index.md" >}}) with Crunchy Postgres for Kubernetes. We recommend [forking the Postgres Operator examples](https://github.com/CrunchyData/postgres-operator-examples/fork) repo.

## Features

- Some network filesystems are sensitive to Linux user and group permissions. Process GIDs can now be configured through `PostgresCluster.spec.supplementalGroups` for when your PVs don't advertise their [GID requirements](https://kubernetes.io/docs/tasks/configure-pod-container/configure-persistent-volume-storage/#access-control).
- A replica service is now automatically reconciled for access to PostgreSQL replicas within a cluster.
- The PostgreSQL primary service and PgBouncer service can now each be configured to have either a `ClusterIP`, `NodePort` or `LoadBalancer` service type. Suggested by Bryan A. S. (@bryanasdev000).
- Pod Topology Spread Constraints can now be specified for PostgreSQL instances, the pgBackRest dedicated repository host as well as PgBouncer.
-  Existing `PGDATA`, Write-Ahead Log (WAL) and pgBackRest repository volumes can now be migrated from PGO v4 to PGO v5 by specifying an `existingVolumes` data source when creating a PostgresCluster.
- There is now a migration guide avaialble for moving Postgres clusters between PGO v4 to PGO v5.
- Custom resource requests and limits can now be configured for all `init` containers, therefore ensuring the desired Quality of Service (QoS) class can be assigned to the various Pods comprising a cluster.
- Custom resource requests and limits can now be configured for all Jobs created for a PostgresCluster.
- A Pod Priority Class can now be configured for the various Pods created for a PostgresCluster.
- An `imagePullPolicy` can now be configured for the various Pods created for a PostgresCluster.
- The pgAudit extension is now enabled by default in all clusters.
- Additional validation has been added to the various PVC definitions within the PostgresCluster spec to ensure successful PVC reconciliation.
- A custom SQL script can be configured to run when a PostgresCluster is initialized.
- PostgreSQL server certificates are now automatically reloaded when they change.

## Changes

- The supplemental group `65534` is no longer applied by default. Upgrading the operator will perform a rolling update on all PostgresClusters to remove it.

  If you need this GID for your network filesystem, you should perform the following steps when upgrading:

  1. Before deploying the new operator, deploy the new CRD. You can get the new CRD from the [Postgres Operator Examples](https://github.com/CrunchyData/postgres-operator-examples/fork) repository and executing the following command:
     ```console
     $ kubectl apply -k kustomize/install
     ```

  2. Add the group to your existing PostgresClusters:
     ```console
     $ kubectl edit postgrescluster/hippo

     kind: PostgresCluster
     …
     spec:
       supplementalGroups:
       - 65534
     …
     ```

     _or_

     ```console
     $ kubectl patch postgrescluster/hippo --type=merge --patch='{"spec":{"supplementalGroups":[65534]}}'
     ```

     _or_

     by modifying `spec.supplementalGroups` in your manifest.

  3. Deploy the new operator. If you are using an up-to-date version of the manifest, you can run:
     ```console
     $ kubectl apply -k kustomize/install
     ```

- A dedicated pgBackRest repository host is now only deployed if a `volume` repo is configured.  This means that users with cloud-based (`s3`, `gcs` and/or `azure`) repos only will no longer see a dedicated repository host, nor will `SSHD` rub in any form within that PG cluster.  As a result of this change, the `spec.backups.pgbackrest.repoHost.dedicated` section is removed from the PostgresCluster spec, and all settings within it have been consolidated under section `spec.backups.pgbackrest.repoHost` (which is now only applicable if a dedicated repo host is actually deployed within the PG cluster).  Therefore, when upgrading please update the PostgresCluster spec to ensure any settings from section `spec.backups.pgbackrest.repoHost.dedicated` are moved into section `spec.backups.pgbackrest.repoHost`.
- The PGO documentation now includes an "Administrative Tasks" section, which includes instructions for manually restarting PostgreSQL and rotating TLS certificates.
- PgBouncer now uses SCRAM when authenticating into PostgreSQL.

## Fixes

- Validation for the PostgresCluster spec is updated to ensure at least one repo is always defined for section `spec.backups.pgbackrest.repos`.
- A restore will now complete successfully If `max_connections` and/or `max_worker_processes` is configured to a value higher than the default when backing up the PostgreSQL database. Reported by Tiberiu Patrascu (@tpatrascu).
- The installation documentation now properly defines how to set the `PGO_TARGET_NAMESPACE` environment variable for a single namespace installation.
- Ensure the full allocation of shared memory is available to Postgres containers.
